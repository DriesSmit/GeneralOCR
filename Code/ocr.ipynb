{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages and load rotation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "#Life is good\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "#from pytesseract import image_to_string\n",
    "#from pytesseract import image_to_boxes\n",
    "#from pytesseract import image_to_data\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def orientationScore(image,skipStep = 10):\n",
    "    totValue = 0\n",
    "    for row in range(len(image)):\n",
    "        rowVal = 0\n",
    "        for col in range(0,len(image[0]),skipStep):\n",
    "            rowVal += image[row][col]\n",
    "        totValue += rowVal*rowVal\n",
    "    return totValue\n",
    "\n",
    "def findOrient(image,angleRange = 5,skipStep = 10):\n",
    "    maxValue = -1\n",
    "    maxRot  = 0\n",
    "    imageRows, imageCols = image.shape\n",
    "    accuracy = 0.1\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(-1, angleRange*2*int(1/accuracy)):\n",
    "        #rot = i\n",
    "        rot = (round(i / 2 - 0.4) + 1) * ((-1) * (i % 2) + ((i + 1) % 2)) * 0.1\n",
    "        #print rot\n",
    "        # print(\"Rotation: \",rot,\". i: \",i)\n",
    "        M = cv2.getRotationMatrix2D((imageCols / 2, imageRows / 2), rot, 1)\n",
    "        dst = cv2.warpAffine(image, M, (imageCols, imageRows), borderValue=(255, 255, 255))\n",
    "\n",
    "        value = orientationScore(255-dst,skipStep = 10)\n",
    "        if value>maxValue:\n",
    "            maxValue = value\n",
    "            maxRot = rot\n",
    "        #print \"Current angle: \",rot,\". Current value: \", value,\". Max value: \",maxValue,\". Max rot: \",maxRot\n",
    "        #cv2.imshow(\"Rotated Image: \",dst)\n",
    "        #cv2.waitKey(0)\n",
    "\n",
    "    M = cv2.getRotationMatrix2D((imageCols / 2, imageRows / 2), maxRot, 1)\n",
    "    dst = cv2.warpAffine(image, M, (imageCols, imageRows), borderValue=(255, 255, 255))\n",
    "    #cv2.imshow(\"Rotated Image: \", dst)\n",
    "    #cv2.waitKey(0)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the paramaters of the OCR run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "#args[\"image\"] = \"/home/dries/devel/PraelexisOCR/Code/rotate.png\"\n",
    "args[\"image\"] = \"/home/dries/devel/PraelexisOCR/Code/rotatedDistorted.png\"\n",
    "#args[\"image\"] = \"/home/dries/devel/PraelexisOCR/Code/RealScan.jpg\"\n",
    "#args[\"image\"] = \"/home/dries/devel/PraelexisOCR/Code/phonePhoto.jpg\"\n",
    "args[\"preprocess\"] = \"thresh\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding orientation..\n",
      "Image corrected. Scanning image..\n",
      "Text:  mwhmmmmmmmhmmm\n",
      "\n",
      "lumxn.wm—.wmlwvdnuﬁnllwmmam-nmd\n",
      "mumeMWMMammmMmm,.nmmp-MMm\n",
      "mmu-mxmmmcmmmmmx. mmnmm\n",
      "Mnemuwmmmmmam‘mlmmm. (Samara\n",
      "mmnmm mewnnm') mumwnmmdumﬂapm\n",
      "mmnmmu-mvumhmMp-mmnuumopmw\n",
      "Mm: wm mluumn n: mu nu much um. um pan-mg. l mug:\n",
      "muwwmvﬂmmMmMme:kﬂm\n",
      "mmmmmmmummmwmmwmmmm\n",
      "mwmylumumlauupy\n",
      "\n",
      "InlmmlmnllnlnMnlwumhmmlmmmnmlmm\n",
      "mvmmmhxpmlmb:\n",
      "m   1.63333333333   (48, 47)\n",
      "w   0.866666666667   (90, 47)\n",
      "b   0.333333333333   (108, 46)\n",
      "m   0.533333333333   (124, 46)\n",
      "W   0.6   (145, 46)\n",
      "W   1.56666666667   (180, 50)\n",
      "U   0.333333333333   (213, 46)\n",
      "M   1.03333333333   (236, 46)\n",
      "M   0.333333333333   (260, 44)\n",
      "E   0.566666666667   (277, 47)\n",
      "M   0.866666666667   (303, 47)\n",
      "I   0.233333333333   (321, 44)\n",
      "m   0.5   (331, 46)\n",
      "K   0.333333333333   (344, 46)\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character u'\\u2018' in position 0: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-fec013e9149e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m#print(\"Here: \",entry[0], \" \", len(entry[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;31m#print ord(entry[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character u'\\u2018' in position 0: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "\n",
    "# construct the argument parse and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-i\", \"--image\", required=True,help=\"path to input image to be OCR'd\")\n",
    "# ap.add_argument(\"-p\", \"--preprocess\", type=str, default=\"thresh\",\thelp=\"type of preprocessing to be done\")\n",
    "# args = vars(ap.parse_args())s\n",
    "\n",
    "\n",
    "# load the example image and convert it to grayscale\n",
    "image = cv2.imread(args[\"image\"])\n",
    "\n",
    "# cv2.imshow(\"Image\", image)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "print(\"Finding orientation..\")\n",
    "gray = findOrient(gray,angleRange = 20,skipStep = 10)\n",
    "print(\"Image corrected. Scanning image..\")\n",
    "# check to see if we should apply thresholding to preprocess the\n",
    "# image\n",
    "if args[\"preprocess\"] == \"thresh\":\n",
    "    gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# make a check to see if median blurring should be done to remove\n",
    "# noise\n",
    "elif args[\"preprocess\"] == \"blur\":\n",
    "    gray = cv2.medianBlur(gray, 1)\n",
    "\n",
    "'''cv2.namedWindow('Input', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Input\", gray)    \n",
    "cv2.waitKey(0)'''\n",
    "\n",
    "\n",
    "\n",
    "# write the grayscale image to disk as a temporary file so we can\n",
    "# apply OCR to it\n",
    "#filename = \"{}.png\".format(os.getpid())\n",
    "#cv2.imwrite(filename, gray)\n",
    "\n",
    "# load the image as a PIL/Pillow image, apply OCR, and then delete\n",
    "# the temporary file\n",
    "#text = pytesseract.image_to_string(gray,boxes=False)\n",
    "\n",
    "\n",
    "# This might not be the best approach. I think the system also directly searches for words.\n",
    "# These word phrases are not included in the config settings.\n",
    "#con =\"-c tessedit_char_whitelist=0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLNMOPQRSTUVWXYZ-+,.()&:\"\n",
    "\n",
    "text = pytesseract.image_to_string(gray,boxes=False)#,config=con)\n",
    "data = pytesseract.image_to_string(gray,boxes=True)#,config=con)\n",
    "\n",
    "lines = data.split('\\n')\n",
    "\n",
    "print \"Text: \", text\n",
    "\n",
    "array = []\n",
    "\n",
    "\n",
    "yLen = len(gray)\n",
    "newPage = gray.copy()\n",
    "\n",
    "for i in range(len(newPage)):\n",
    "    for j in range(len(newPage[0])):\n",
    "        newPage[i][j] = 255\n",
    "\n",
    "for line in lines:\n",
    "    entry = line.split(' ')\n",
    "    #print(entry)\n",
    "    array.append(entry)\n",
    "    cv2.rectangle(gray, (int(entry[1]), yLen-int(entry[2])), (int(entry[3]), yLen-int(entry[4])), (0,0,0), 4)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    #print(\"Here: \",entry[0], \" \", len(entry[0]))\n",
    "    if len(str(entry[0]))==1 and ord(entry[0])<128:\n",
    "        #print ord(entry[0])\n",
    "        char = str(entry[0])\n",
    "        #print(char)\n",
    "        \n",
    "        xSize = 0.5*(int(entry[3])-int(entry[1]))\n",
    "        ySize = 0.5*(int(entry[4])-int(entry[2]))\n",
    "        \n",
    "        size = xSize\n",
    "        \n",
    "        if ySize>xSize:\n",
    "            size = ySize\n",
    "        \n",
    "        fondSize = size/15.0\n",
    "        loc = (int(entry[1])+int(0.5*(int(entry[3])-int(entry[1]))),yLen-int(entry[2])+int(0.5*(int(entry[4])-int(entry[2]))))\n",
    "        cv2.putText(newPage,char,loc,font, fondSize,(0,0,255))\n",
    "        print char,\" \",fondSize, \" \", loc\n",
    "    else:\n",
    "        print \"Not added: \",entry\n",
    "        xSize = 0.5*(int(entry[3])-int(entry[1]))\n",
    "        ySize = 0.5*(int(entry[4])-int(entry[2]))\n",
    "        \n",
    "        size = xSize\n",
    "        \n",
    "        if ySize>xSize:\n",
    "            size = ySize\n",
    "        \n",
    "        fondSize = size/15.0\n",
    "        loc = (int(entry[1])+int(0.5*(int(entry[3])-int(entry[1]))),yLen-int(entry[2])+int(0.5*(int(entry[4])-int(entry[2]))))\n",
    "        cv2.putText(newPage,'???',loc,font, fondSize,(0,0,255))\n",
    "        \n",
    "        \n",
    "#data = pytesseract.image_to_boxes(gray)\n",
    "#os.remove(filename)\n",
    "#print \"Text found:\\n\",text\n",
    "\n",
    "#print \"Data:\\n\",array\n",
    "# show the output images\n",
    "\n",
    "#for entry in data:\n",
    "    #print \"Entry: \", entry\n",
    "    #cv2.rectangle(gray, (100, 100), (1000, 1000), (0,0,0), 20)\n",
    "#cv2.namedWindow('Input', cv2.WINDOW_NORMAL)\n",
    "#cv2.imshow(\"Input\", gray)\n",
    "cv2.imwrite('Boxes.png',gray)\n",
    "cv2.imwrite('Estimation.png',newPage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##pytesseract.image_to_string??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
