{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages and load rotation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "#from pytesseract import image_to_string\n",
    "#from pytesseract import image_to_boxes\n",
    "#from pytesseract import image_to_data\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "\n",
    "def generateImage(numImages=1):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    page = np.full((2000,2000),0,dtype=np.int64)\n",
    "    \n",
    "    fondSize = 4\n",
    "    char = \"A\"\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    location = (500,500)\n",
    "    \n",
    "    cv2.putText(page,char,location,font, fondSize,(0,0,255))\n",
    "    \n",
    "    images.append(page)\n",
    "    labels.append(char)\n",
    "    \n",
    "    return images,labels\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def orientationScore(image,skipStep = 10):\n",
    "    totValue = 0\n",
    "    for row in range(len(image)):\n",
    "        rowVal = 0\n",
    "        for col in range(0,len(image[0]),skipStep):\n",
    "            rowVal += image[row][col]\n",
    "        totValue += rowVal*rowVal\n",
    "    return totValue\n",
    "\n",
    "def findOrient(image,angleRange = 5,skipStep = 10):\n",
    "    maxValue = -1\n",
    "    maxRot  = 0\n",
    "    imageRows, imageCols = image.shape\n",
    "    accuracy = 0.1\n",
    "\n",
    "\n",
    "    \n",
    "    maxLen = angleRange*2*int(1/accuracy)\n",
    "    #print maxLen\n",
    "    for i in range(-1, maxLen):\n",
    "        #rot = i\n",
    "        rot = (round(i / 2 - 0.4) + 1) * ((-1) * (i % 2) + ((i + 1) % 2)) * 0.1\n",
    "        #print rot\n",
    "        # print(\"Rotation: \",rot,\". i: \",i)\n",
    "        M = cv2.getRotationMatrix2D((imageCols / 2, imageRows / 2), rot, 1)\n",
    "        dst = cv2.warpAffine(image, M, (imageCols, imageRows), borderValue=(255, 255, 255))\n",
    "\n",
    "        value = orientationScore(255-dst,skipStep = 10)\n",
    "        if value>maxValue:\n",
    "            maxValue = value\n",
    "            maxRot = rot\n",
    "        if  maxRot != 0 and i%int(maxLen/100)==0:\n",
    "            print \"Percentage complete: \", round(i*100.0/maxLen),\"%. Current angle (degree): \",rot\n",
    "        #print \"Current angle: \",rot,\". Current value: \", value,\". Max value: \",maxValue,\". Max rot: \",maxRot\n",
    "        #cv2.imshow(\"Rotated Image: \",dst)\n",
    "        #cv2.waitKey(0)\n",
    "\n",
    "    M = cv2.getRotationMatrix2D((imageCols / 2, imageRows / 2), maxRot, 1)\n",
    "    dst = cv2.warpAffine(image, M, (imageCols, imageRows), borderValue=(255, 255, 255))\n",
    "    #cv2.imshow(\"Rotated Image: \", dst)\n",
    "    #cv2.waitKey(0)\n",
    "    return dst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the paramaters of the OCR run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "#args[\"image\"] = \"/home/dries/devel/Praelexis/OCR/Images/rotate.png\"\n",
    "#args[\"image\"] = \"/home/dries/devel/Praelexis/OCR/Images/rotatedDistorted.png\"\n",
    "#args[\"image\"] = \"/home/dries/devel/Praelexis/OCR/Images/RealScan.jpg\"\n",
    "#args[\"image\"] = \"/home/dries/devel/Praelexis/OCR/Images/phonePhoto.jpg\"\n",
    "#args[\"image\"] = \"/home/dries/devel/Praelexis/OCR/Images/bankRotatedBackround.jpg\"\n",
    "args[\"image\"] = \"/home/dries/devel/Praelexis/OCR/Images/testText.jpg\"\n",
    "args[\"preprocess\"] = \"\"\n",
    "args[\"rotationSearch\"] = 30\n",
    "con =\"-psm 1 --oem 2 -c tessedit_char_whitelist=0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLNMOPQRSTUVWXYZ-+,.()&:_/\\*@\"\n",
    "lan = \"afr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  A\n",
      "Finding orientation..\n",
      "Image corrected. Scanning image..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# construct the argument parse and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-i\", \"--image\", required=True,help=\"path to input image to be OCR'd\")\n",
    "# ap.add_argument(\"-p\", \"--preprocess\", type=str, default=\"thresh\",\thelp=\"type of preprocessing to be done\")\n",
    "# args = vars(ap.parse_args())s\n",
    "\n",
    "grayImages,labels = generateImage(1)\n",
    "\n",
    "for i in range(len(grayImages)):\n",
    "    cv2.namedWindow('Image', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"Image\", grayImages[i])    \n",
    "    print \"Label: \",labels[i]\n",
    "    print(\"Image: \"grayImages[i])\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "# load the example image and convert it to grayscale\n",
    "image = cv2.imread(args[\"image\"])\n",
    "\n",
    "# cv2.imshow(\"Image\", image)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#findObjects(gray)\n",
    "cv2.imwrite('/home/dries/devel/Praelexis/OCR/Output/Original.png',gray)\n",
    "print(\"Finding orientation..\")\n",
    "gray = findOrient(gray,angleRange = args[\"rotationSearch\"],skipStep = 10)\n",
    "print(\"Image corrected. Scanning image..\")\n",
    "# check to see if we should apply thresholding to preprocess the\n",
    "# image\n",
    "if args[\"preprocess\"] == \"thresh\":\n",
    "    gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# make a check to see if median blurring should be done to remove\n",
    "# noise\n",
    "elif args[\"preprocess\"] == \"blur\":\n",
    "    gray = cv2.medianBlur(gray, 1)\n",
    "\n",
    "'''cv2.namedWindow('Input', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Input\", gray)    \n",
    "cv2.waitKey(0)'''\n",
    "\n",
    "\n",
    "\n",
    "# write the grayscale image to disk as a temporary file so we can\n",
    "# apply OCR to it\n",
    "#filename = \"{}.png\".format(os.getpid())\n",
    "#cv2.imwrite(filename, gray)\n",
    "\n",
    "# load the image as a PIL/Pillow image, apply OCR, and then delete\n",
    "# the temporary file\n",
    "#text = pytesseract.image_to_string(gray,boxes=False)\n",
    "\n",
    "\n",
    "# This might not be the best approach. I think the system also directly searches for words.\n",
    "# These word phrases are not included in the config settings.\n",
    "\n",
    "cv2.imwrite('/home/dries/devel/Praelexis/OCR/Output/preProcessed.png',gray)\n",
    "\n",
    "text = pytesseract.image_to_string(gray,lang=lan,boxes=False,config=con)\n",
    "\n",
    "f = open('/home/dries/devel/Praelexis/OCR/Output/outputText.txt','w')\n",
    "f.write(text)\n",
    "f.close()\n",
    "\n",
    "#print \"Text: \", text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets generate a output image of what the system sees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed. Output in folder named 'Output'.\n"
     ]
    }
   ],
   "source": [
    "data = pytesseract.image_to_string(gray,boxes=True,config=con)\n",
    "lines = data.split('\\n')\n",
    "\n",
    "array = []\n",
    "\n",
    "\n",
    "yLen = len(gray)\n",
    "newPage = gray.copy()\n",
    "\n",
    "for i in range(len(newPage)):\n",
    "    for j in range(len(newPage[0])):\n",
    "        newPage[i][j] = 255\n",
    "\n",
    "for line in lines:\n",
    "    entry = line.split(' ')\n",
    "    #print(entry)\n",
    "    array.append(entry)\n",
    "    cv2.rectangle(gray, (int(entry[1]), yLen-int(entry[2])), (int(entry[3]), yLen-int(entry[4])), (0,0,0), 1)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    #print(\"Here: \",entry[0], \" \", len(entry[0]))\n",
    "    try:\n",
    "        char = str(entry[0])\n",
    "        #print(char)\n",
    "        \n",
    "        xSize = 0.5*(int(entry[3])-int(entry[1]))\n",
    "        ySize = 0.5*(int(entry[4])-int(entry[2]))\n",
    "        \n",
    "        size = xSize\n",
    "        \n",
    "        if ySize>xSize:\n",
    "            size = ySize\n",
    "        \n",
    "        fondSize = size/15.0\n",
    "        loc = (int(entry[1])+int(0.5*(int(entry[3])-int(entry[1]))),yLen-int(entry[2])+int(0.5*(int(entry[4])-int(entry[2]))))\n",
    "        cv2.putText(newPage,char,loc,font, fondSize,(0,0,255))\n",
    "        #print char,\" \",fondSize, \" \", loc\n",
    "    except (TypeError, ValueError):\n",
    "        print \"Not added: \",entry\n",
    "        xSize = 0.5*(int(entry[3])-int(entry[1]))\n",
    "        ySize = 0.5*(int(entry[4])-int(entry[2]))\n",
    "        \n",
    "        size = xSize\n",
    "        \n",
    "        if ySize>xSize:\n",
    "            size = ySize\n",
    "        \n",
    "        fondSize = size/15.0\n",
    "        loc = (int(entry[1])+int(0.5*(int(entry[3])-int(entry[1]))),yLen-int(entry[2])+int(0.5*(int(entry[4])-int(entry[2]))))\n",
    "        cv2.putText(newPage,'???',loc,font, fondSize,(0,0,255))\n",
    "        \n",
    "        \n",
    "#data = pytesseract.image_to_boxes(gray)\n",
    "#os.remove(filename)\n",
    "#print \"Text found:\\n\",text\n",
    "\n",
    "#print \"Data:\\n\",array\n",
    "# show the output images\n",
    "\n",
    "#for entry in data:\n",
    "    #print \"Entry: \", entry\n",
    "    #cv2.rectangle(gray, (100, 100), (1000, 1000), (0,0,0), 20)\n",
    "#cv2.namedWindow('Input', cv2.WINDOW_NORMAL)\n",
    "#cv2.imshow(\"Input\", gray)\n",
    "cv2.imwrite('/home/dries/devel/Praelexis/OCR/Output/Boxes.png',gray)\n",
    "cv2.imwrite('/home/dries/devel/Praelexis/OCR/Output/Estimation.png',newPage)\n",
    "print(\"Completed. Output in folder named 'Output'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytesseract.pytesseract??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
