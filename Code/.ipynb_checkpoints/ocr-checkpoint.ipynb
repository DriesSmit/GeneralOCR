{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages and load rotation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "#Life is good\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "#from pytesseract import image_to_string\n",
    "#from pytesseract import image_to_boxes\n",
    "#from pytesseract import image_to_data\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "\n",
    "def orientationScore(image,skipStep = 10):\n",
    "    totValue = 0\n",
    "    for row in range(len(image)):\n",
    "        rowVal = 0\n",
    "        for col in range(0,len(image[0]),skipStep):\n",
    "            rowVal += image[row][col]\n",
    "        totValue += rowVal*rowVal\n",
    "    return totValue\n",
    "\n",
    "def findOrient(image,angleRange = 5,skipStep = 10):\n",
    "    maxValue = -1\n",
    "    maxRot  = 0\n",
    "    imageRows, imageCols = image.shape\n",
    "    accuracy = 0.1\n",
    "\n",
    "\n",
    "    \n",
    "    maxLen = angleRange*2*int(1/accuracy)\n",
    "    #print maxLen\n",
    "    for i in range(-1, maxLen):\n",
    "        #rot = i\n",
    "        rot = (round(i / 2 - 0.4) + 1) * ((-1) * (i % 2) + ((i + 1) % 2)) * 0.1\n",
    "        #print rot\n",
    "        # print(\"Rotation: \",rot,\". i: \",i)\n",
    "        M = cv2.getRotationMatrix2D((imageCols / 2, imageRows / 2), rot, 1)\n",
    "        dst = cv2.warpAffine(image, M, (imageCols, imageRows), borderValue=(255, 255, 255))\n",
    "\n",
    "        value = orientationScore(255-dst,skipStep = 10)\n",
    "        if value>maxValue:\n",
    "            maxValue = value\n",
    "            maxRot = rot\n",
    "        if  maxRot != 0 and i%int(maxLen/100)==0:\n",
    "            print \"Percentage complete: \", round(i*100.0/maxLen),\"%. Current angle (degree): \",rot\n",
    "        #print \"Current angle: \",rot,\". Current value: \", value,\". Max value: \",maxValue,\". Max rot: \",maxRot\n",
    "        #cv2.imshow(\"Rotated Image: \",dst)\n",
    "        #cv2.waitKey(0)\n",
    "\n",
    "    M = cv2.getRotationMatrix2D((imageCols / 2, imageRows / 2), maxRot, 1)\n",
    "    dst = cv2.warpAffine(image, M, (imageCols, imageRows), borderValue=(255, 255, 255))\n",
    "    #cv2.imshow(\"Rotated Image: \", dst)\n",
    "    #cv2.waitKey(0)\n",
    "    return dst\n",
    "\n",
    "def changeTarget(image, imageClass, checkList, curLoc, targetLoc, condition):\n",
    "      if imageClass[targetLoc[0]][targetLoc[1]] < 0.01 and image[targetLoc[0]][targetLoc[1]] > condition:\n",
    "          #print(imageClass[curLoc[0]][curLoc[1]])\n",
    "          imageClass[targetLoc[0]][targetLoc[1]] = imageClass[curLoc[0]][curLoc[1]]\n",
    "          checkList.append((targetLoc[0], targetLoc[1]))\n",
    "\n",
    "def checkAndChange(image, imageClass, checkList, condition):\n",
    "  curLoc = checkList.pop(len(checkList)-1)\n",
    "  i = curLoc[0]\n",
    "  j = curLoc[1]\n",
    "  if i > 0:\n",
    "      if j > 0:\n",
    "          changeTarget(image, imageClass, checkList, curLoc, (i - 1, j - 1), condition)\n",
    "      changeTarget(image, imageClass, checkList, curLoc, (i - 1, j), condition)\n",
    "      if j < len(image[0]) - 1:\n",
    "          changeTarget(image, imageClass, checkList, curLoc, (i - 1, j + 1), condition)\n",
    "  if i < len(image) - 1:\n",
    "      if j > 0:\n",
    "          changeTarget(image, imageClass, checkList, curLoc, (i + 1, j - 1), condition)\n",
    "      changeTarget(image, imageClass, checkList, curLoc, (i + 1, j), condition)\n",
    "      if j < len(image[0]) - 1:\n",
    "          changeTarget(image, imageClass, checkList, curLoc, (i + 1, j + 1), condition)\n",
    "  if j > 0:\n",
    "      changeTarget(image, imageClass, checkList, curLoc, (i, j - 1), condition)\n",
    "  if j < len(image[0]) - 1:\n",
    "      changeTarget(image, imageClass, checkList, curLoc, (i, j + 1), condition)\n",
    "\n",
    "def findObjects(image):\n",
    "  cv2.namedWindow(\"Before image\", cv2.WINDOW_NORMAL)\n",
    "  cv2.imshow(\"Before image\", image)\n",
    "  #print(\"Shape of image:\", image)\n",
    "\n",
    "  image = 1.0 - image\n",
    "  total = 0.0\n",
    "  for i in range(len(image)):\n",
    "      for j in range(len(image[0])):\n",
    "          total = total + image[i][j]\n",
    "\n",
    "  mean = total / (len(image) * len(image[0]))\n",
    "  imageClass = np.zeros((len(image), len(image[0])))\n",
    "  count = 0\n",
    "  checkList = []\n",
    "  condition = mean\n",
    "  for i in range(len(image)):\n",
    "      for j in range(len(image[0])):\n",
    "          if image[i][j] > condition and imageClass[i][j] < 0.01:\n",
    "              checkList.append((i, j))\n",
    "              count = count + 1\n",
    "              imageClass[i][j] = count\n",
    "              #print(\"Count: \",count, \". i: \", i , \". j: \", j)\n",
    "              numPix = 0\n",
    "              while len(checkList) > 0:\n",
    "                  numPix += 1\n",
    "                  checkAndChange(image, imageClass, checkList, condition)\n",
    "              print numPix\n",
    "              if numPix >100:\n",
    "                  curImage = 1.0 - imageClass / count\n",
    "                  cv2.namedWindow(\"Cur image\", cv2.WINDOW_NORMAL)\n",
    "                  cv2.imshow(\"Cur image\", curImage)\n",
    "                  print(\"Waiting..\")\n",
    "                  cv2.waitKey(0)\n",
    "                  print(\"Thinking..\")\n",
    "\n",
    "  classStats = np.zeros((count,7))\n",
    "\n",
    "  for i in range(count):\n",
    "      classStats[i][3] = 10000.0\n",
    "      classStats[i][4] = 10000.0\n",
    "      classStats[i][5] = -1.0\n",
    "      classStats[i][6] = -1.0\n",
    "\n",
    "\n",
    "  for i in range(len(image)):\n",
    "      for j in range(len(image[0])):\n",
    "        if imageClass[i][j]>0.01:\n",
    "            classStats[int(imageClass[i][j]+0.0001)-1][0] += image[i][j] #total pixels\n",
    "            classStats[int(imageClass[i][j]+0.0001)-1][1] += j*image[i][j] #can get xMean from this\n",
    "            classStats[int(imageClass[i][j]+0.0001)-1][2] += i*image[i][j] #can get yMean from this\n",
    "\n",
    "            left = classStats[int(imageClass[i][j]+0.0001)-1][3]\n",
    "            up = classStats[int(imageClass[i][j]+0.0001)-1][4]\n",
    "            right = classStats[int(imageClass[i][j]+0.0001)-1][5]\n",
    "            down = classStats[int(imageClass[i][j]+0.0001)-1][6]\n",
    "\n",
    "            if j < left:\n",
    "                classStats[int(imageClass[i][j]+0.0001) - 1][3] = j\n",
    "            if i < up:\n",
    "                classStats[int(imageClass[i][j]+0.0001) - 1][4] = i\n",
    "            if j > right:\n",
    "                classStats[int(imageClass[i][j]+0.0001) - 1][5] = j\n",
    "            if i > down:\n",
    "                classStats[int(imageClass[i][j]+0.0001) - 1][6] = i\n",
    "\n",
    "  bestScore = 0.0\n",
    "  bestIndex = 0\n",
    "\n",
    "  bestCoor = [0,0,0,0]\n",
    "  bestMean = (0, 0)\n",
    "\n",
    "  for i in range(count):\n",
    "      #print(classStats[i])\n",
    "      total = classStats[i][0]\n",
    "      #meanX = classStats[i][1]/total\n",
    "      #meanY = classStats[i][2]/total\n",
    "      #distFromCen = math.sqrt(math.pow(meanX-len(image[0])/2.0,2.0)+math.pow(meanY-len(image)/2.0,2.0))\n",
    "      #score = total-0.5*distFromCen\n",
    "      #print(total, \" \",distFromCen)\n",
    "      if score > bestScore:\n",
    "          #print(\"Index: \",i,\". Score: \",score)\n",
    "          bestIndex = i+1\n",
    "          bestScore = score\n",
    "          bestCoor[0] = int(classStats[i][3])\n",
    "          bestCoor[1] = int(classStats[i][4])\n",
    "          bestCoor[2] = int(classStats[i][5])\n",
    "          bestCoor[3] = int(classStats[i][6])\n",
    "          bestMean = (meanX,meanY)\n",
    "  finalImage = np.zeros((len(image), len(image[0])))\n",
    "\n",
    "  for i in range(len(image)):\n",
    "      for j in range(len(image[0])):\n",
    "        #print(int(imageClass[i][j]+0.001),\"   \", imageClass[i][j],\"    \",bestIndex)\n",
    "        if int(imageClass[i][j]+0.001)==bestIndex:\n",
    "            finalImage[i][j] = image[i][j]\n",
    "\n",
    "  image = 1.0 - finalImage\n",
    "\n",
    "  image = np.power(image,20)\n",
    "\n",
    "  cv2.namedWindow(\"Filtered for digit\", cv2.WINDOW_NORMAL)\n",
    "  cv2.imshow(\"Filtered for digit\", image)\n",
    "  cv2.waitKey(0)\n",
    "\n",
    "  #imgCopy = image.copy()\n",
    "  #print(bestCoor)\n",
    "  #cv2.rectangle(imgCopy, (bestCoor[0], bestCoor[1]), (bestCoor[2], bestCoor[3]),(0.8, 0.8, 0.8), 2)\n",
    "  #cv2.namedWindow(\"Rectangle image\", cv2.WINDOW_NORMAL)\n",
    "  #cv2.imshow(\"Rectangle image\", imgCopy)\n",
    "  #cv2.waitKey(0)\n",
    "\n",
    "  # Put digit in center of screen convert to 1D array:\n",
    "  OriginalCen = (int(round(len(image[0]) / 2.0)), int(round(len(image)/2.0)))\n",
    "  #print(\"Image centre: \",OriginalCen)\n",
    "  centre = (int(round((bestCoor[0]+bestCoor[2])/2.0)),int(round((bestCoor[1]+bestCoor[3])/2.0)))\n",
    "  oldcentre = (int(round(bestMean[0])), int(round(bestMean[1])))\n",
    "  #print(\"Old center: \",oldcentre)\n",
    "  #print(\"New center: \", centre)\n",
    "\n",
    "  offSet = (-centre[0] + OriginalCen[0], -centre[1] + OriginalCen[1])\n",
    "  #print(\"Change: \",offSet)\n",
    "  rows, cols = image.shape\n",
    "  #print(\"One: \", len(image), \" \", len(image[0]))\n",
    "\n",
    "  M = np.float32([[1, 0, offSet[0]], [0, 1, offSet[1]]])\n",
    "  image = cv2.warpAffine(image, M, (cols, rows), borderValue=(1.0, 1.0, 1.0))\n",
    "  reshapedImage = image\n",
    "  #cv2.namedWindow(\"Moved image\", cv2.WINDOW_NORMAL)\n",
    "  #cv2.imshow(\"Moved image\", reshapedImage)\n",
    "  #cv2.waitKey(0)\n",
    "  #print(\"Two: \", len(image), \" \", len(image[0]))\n",
    "  # Resize image\n",
    "  inlargeConst = 0.7\n",
    "\n",
    "  shrink1 = (bestCoor[3]-bestCoor[1]) / (len(image) * inlargeConst)\n",
    "  shrink2 = (bestCoor[2]-bestCoor[0]) / (len(image[0]) * inlargeConst)\n",
    "\n",
    "  maxShrink = shrink1\n",
    "  if (shrink2 > maxShrink):\n",
    "      maxShrink = shrink2\n",
    "  #print(\"Shrink: \", maxShrink)\n",
    "  if maxShrink < 1.0 and maxShrink >0.01:\n",
    "      minX = int(len(image) / 2.0 - len(image) / 2.0 * maxShrink)\n",
    "      maxX = int(len(image) / 2.0 + len(image) / 2.0 * maxShrink)\n",
    "      minY = int(len(image[0]) / 2.0 - len(image[0]) / 2.0 * maxShrink)\n",
    "      maxY = int(len(image[0]) / 2.0 + len(image[0]) / 2.0 * maxShrink)\n",
    "\n",
    "      image = image[minX:maxX, minY:maxY]\n",
    "  #print(\"Three: \",len(image), \" \", len(image[0]))\n",
    "  reshapedImage = cv2.resize(image, (28, 28))\n",
    "  image = reshapedImage.reshape(1, 784)\n",
    "\n",
    "  '''total = 0.0\n",
    "  for i in range(len(image[0])):\n",
    "      total = total + image[0][i]\n",
    "  mean = total / (28.0 * 28.0)\n",
    "  # print(\"Mean: \",mean)\n",
    "  degree = 10.0\n",
    "  for i in range(len(image[0])):\n",
    "      if (image[0][i] < mean):\n",
    "          image[0][i] = math.pow(image[0][i], degree)\n",
    "      else:\n",
    "          image[0][i] = 1 - math.pow(1.0 - image[0][i], degree)'''\n",
    "  reshapedImage = image[0].reshape(28, 28)\n",
    "  cv2.namedWindow(\"After image\", cv2.WINDOW_NORMAL)\n",
    "  cv2.imshow(\"After image\", reshapedImage)\n",
    "  cv2.waitKey(0)\n",
    "  return (1.0-image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the paramaters of the OCR run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "#args[\"image\"] = \"/home/dries/devel/Praelexis/OCR/Images/rotate.png\"\n",
    "args[\"image\"] = \"/home/dries/devel/Praelexis/OCR/Images/rotatedDistorted.png\"\n",
    "#args[\"image\"] = \"/home/dries/devel/Praelexis/OCR/Images/RealScan.jpg\"\n",
    "#args[\"image\"] = \"/home/dries/devel/Praelexis/OCR/Images/phonePhoto.jpg\"\n",
    "#args[\"image\"] = \"/home/dries/devel/Praelexis/OCR/Images/bankRotatedBackround.jpg\"\n",
    "\n",
    "args[\"preprocess\"] = \"\"\n",
    "args[\"rotationSearch\"] = 30\n",
    "con =\"-psm 1 --oem 2 -c tessedit_char_whitelist=0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLNMOPQRSTUVWXYZ-+,.()&:_/\\*@\"\n",
    "lan = \"afr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "272\n",
      "Waiting..\n",
      "Thinking..\n",
      "204\n",
      "Waiting..\n",
      "Thinking..\n",
      "43\n",
      "294\n",
      "Waiting..\n",
      "Thinking..\n",
      "6\n",
      "195\n",
      "Waiting..\n",
      "Thinking..\n",
      "8\n",
      "181\n",
      "Waiting..\n",
      "Thinking..\n",
      "75\n",
      "72\n",
      "123\n",
      "Waiting..\n",
      "Thinking..\n",
      "314\n",
      "Waiting..\n",
      "Thinking..\n",
      "72\n",
      "186\n",
      "Waiting..\n",
      "Thinking..\n",
      "192\n",
      "Waiting..\n",
      "Thinking..\n",
      "118\n",
      "Waiting..\n",
      "Thinking..\n",
      "143\n",
      "Waiting..\n",
      "Thinking..\n",
      "109\n",
      "Waiting..\n",
      "Thinking..\n",
      "72\n",
      "321\n",
      "Waiting..\n",
      "Thinking..\n",
      "234\n",
      "Waiting..\n",
      "Thinking..\n",
      "72\n",
      "190\n",
      "Waiting..\n",
      "Thinking..\n",
      "171\n",
      "Waiting..\n",
      "Thinking..\n",
      "5\n",
      "74\n",
      "226\n",
      "Waiting..\n",
      "Thinking..\n",
      "53\n",
      "116\n",
      "Waiting..\n",
      "Thinking..\n",
      "114\n",
      "Waiting..\n",
      "Thinking..\n",
      "291\n",
      "Waiting..\n",
      "Thinking..\n",
      "320\n",
      "Waiting..\n",
      "Thinking..\n",
      "107\n",
      "Waiting..\n",
      "Thinking..\n",
      "259\n",
      "Waiting..\n",
      "Thinking..\n",
      "171\n",
      "Waiting..\n",
      "Thinking..\n",
      "132\n",
      "Waiting..\n",
      "Thinking..\n",
      "339\n",
      "Waiting..\n",
      "Thinking..\n",
      "145\n",
      "Waiting..\n",
      "Thinking..\n",
      "99\n",
      "6\n",
      "210\n",
      "Waiting..\n",
      "Thinking..\n",
      "89\n",
      "448\n",
      "Waiting..\n",
      "Thinking..\n",
      "282\n",
      "Waiting..\n",
      "Thinking..\n",
      "5\n",
      "284\n",
      "Waiting..\n",
      "Thinking..\n",
      "195\n",
      "Waiting..\n",
      "Thinking..\n",
      "115\n",
      "Waiting..\n",
      "Thinking..\n",
      "220\n",
      "Waiting..\n",
      "Thinking..\n",
      "202\n",
      "Waiting..\n",
      "Thinking..\n",
      "6\n",
      "345\n",
      "Waiting..\n",
      "Thinking..\n",
      "314\n",
      "Waiting..\n",
      "Thinking..\n",
      "154\n",
      "Waiting..\n",
      "Thinking..\n",
      "5\n",
      "183\n",
      "Waiting..\n",
      "Thinking..\n",
      "4\n",
      "323\n",
      "Waiting..\n",
      "Thinking..\n",
      "437\n",
      "Waiting..\n",
      "Thinking..\n",
      "286\n",
      "Waiting..\n",
      "Thinking..\n",
      "77\n",
      "172\n",
      "Waiting..\n",
      "Thinking..\n",
      "4\n",
      "584\n",
      "Waiting..\n",
      "Thinking..\n",
      "474\n",
      "Waiting..\n",
      "Thinking..\n",
      "126\n",
      "Waiting..\n",
      "Thinking..\n",
      "90\n",
      "140\n",
      "Waiting..\n",
      "Thinking..\n",
      "148\n",
      "Waiting..\n",
      "Thinking..\n",
      "5\n",
      "281\n",
      "Waiting..\n",
      "Thinking..\n",
      "430\n",
      "Waiting..\n",
      "Thinking..\n",
      "5\n",
      "172\n",
      "Waiting..\n",
      "Thinking..\n",
      "209\n",
      "Waiting..\n",
      "Thinking..\n",
      "83\n",
      "123\n",
      "Waiting..\n",
      "Thinking..\n",
      "6\n",
      "369\n",
      "Waiting..\n",
      "Thinking..\n",
      "75\n",
      "181\n",
      "Waiting..\n",
      "Thinking..\n",
      "327\n",
      "Waiting..\n",
      "Thinking..\n",
      "113\n",
      "Waiting..\n",
      "Thinking..\n",
      "6\n",
      "184\n",
      "Waiting..\n",
      "Thinking..\n",
      "157\n",
      "Waiting..\n",
      "Thinking..\n",
      "6\n",
      "187\n",
      "Waiting..\n",
      "Thinking..\n",
      "149\n",
      "Waiting..\n",
      "Thinking..\n",
      "370\n",
      "Waiting..\n",
      "Thinking..\n",
      "163\n",
      "Waiting..\n",
      "Thinking..\n",
      "80\n",
      "19\n",
      "34\n",
      "4\n",
      "307\n",
      "Waiting..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# construct the argument parse and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-i\", \"--image\", required=True,help=\"path to input image to be OCR'd\")\n",
    "# ap.add_argument(\"-p\", \"--preprocess\", type=str, default=\"thresh\",\thelp=\"type of preprocessing to be done\")\n",
    "# args = vars(ap.parse_args())s\n",
    "\n",
    "\n",
    "# load the example image and convert it to grayscale\n",
    "image = cv2.imread(args[\"image\"])\n",
    "\n",
    "# cv2.imshow(\"Image\", image)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "findObjects(gray)\n",
    "cv2.imwrite('/home/dries/devel/Praelexis/OCR/Output/Original.png',gray)\n",
    "print(\"Finding orientation..\")\n",
    "gray = findOrient(gray,angleRange = args[\"rotationSearch\"],skipStep = 10)\n",
    "print(\"Image corrected. Scanning image..\")\n",
    "# check to see if we should apply thresholding to preprocess the\n",
    "# image\n",
    "if args[\"preprocess\"] == \"thresh\":\n",
    "    gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# make a check to see if median blurring should be done to remove\n",
    "# noise\n",
    "elif args[\"preprocess\"] == \"blur\":\n",
    "    gray = cv2.medianBlur(gray, 1)\n",
    "\n",
    "'''cv2.namedWindow('Input', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Input\", gray)    \n",
    "cv2.waitKey(0)'''\n",
    "\n",
    "\n",
    "\n",
    "# write the grayscale image to disk as a temporary file so we can\n",
    "# apply OCR to it\n",
    "#filename = \"{}.png\".format(os.getpid())\n",
    "#cv2.imwrite(filename, gray)\n",
    "\n",
    "# load the image as a PIL/Pillow image, apply OCR, and then delete\n",
    "# the temporary file\n",
    "#text = pytesseract.image_to_string(gray,boxes=False)\n",
    "\n",
    "\n",
    "# This might not be the best approach. I think the system also directly searches for words.\n",
    "# These word phrases are not included in the config settings.\n",
    "\n",
    "cv2.imwrite('/home/dries/devel/Praelexis/OCR/Output/preProcessed.png',gray)\n",
    "\n",
    "text = pytesseract.image_to_string(gray,lang=lan,boxes=False,config=con)\n",
    "\n",
    "f = open('/home/dries/devel/Praelexis/OCR/Output/outputText.txt','w')\n",
    "f.write(text)\n",
    "f.close()\n",
    "\n",
    "#print \"Text: \", text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets generate a output image of what the system sees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pytesseract.image_to_string(gray,boxes=True,config=con)\n",
    "lines = data.split('\\n')\n",
    "\n",
    "array = []\n",
    "\n",
    "\n",
    "yLen = len(gray)\n",
    "newPage = gray.copy()\n",
    "\n",
    "for i in range(len(newPage)):\n",
    "    for j in range(len(newPage[0])):\n",
    "        newPage[i][j] = 255\n",
    "\n",
    "for line in lines:\n",
    "    entry = line.split(' ')\n",
    "    #print(entry)\n",
    "    array.append(entry)\n",
    "    cv2.rectangle(gray, (int(entry[1]), yLen-int(entry[2])), (int(entry[3]), yLen-int(entry[4])), (0,0,0), 1)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    #print(\"Here: \",entry[0], \" \", len(entry[0]))\n",
    "    try:\n",
    "        char = str(entry[0])\n",
    "        #print(char)\n",
    "        \n",
    "        xSize = 0.5*(int(entry[3])-int(entry[1]))\n",
    "        ySize = 0.5*(int(entry[4])-int(entry[2]))\n",
    "        \n",
    "        size = xSize\n",
    "        \n",
    "        if ySize>xSize:\n",
    "            size = ySize\n",
    "        \n",
    "        fondSize = size/15.0\n",
    "        loc = (int(entry[1])+int(0.5*(int(entry[3])-int(entry[1]))),yLen-int(entry[2])+int(0.5*(int(entry[4])-int(entry[2]))))\n",
    "        cv2.putText(newPage,char,loc,font, fondSize,(0,0,255))\n",
    "        #print char,\" \",fondSize, \" \", loc\n",
    "    except (TypeError, ValueError):\n",
    "        print \"Not added: \",entry\n",
    "        xSize = 0.5*(int(entry[3])-int(entry[1]))\n",
    "        ySize = 0.5*(int(entry[4])-int(entry[2]))\n",
    "        \n",
    "        size = xSize\n",
    "        \n",
    "        if ySize>xSize:\n",
    "            size = ySize\n",
    "        \n",
    "        fondSize = size/15.0\n",
    "        loc = (int(entry[1])+int(0.5*(int(entry[3])-int(entry[1]))),yLen-int(entry[2])+int(0.5*(int(entry[4])-int(entry[2]))))\n",
    "        cv2.putText(newPage,'???',loc,font, fondSize,(0,0,255))\n",
    "        \n",
    "        \n",
    "#data = pytesseract.image_to_boxes(gray)\n",
    "#os.remove(filename)\n",
    "#print \"Text found:\\n\",text\n",
    "\n",
    "#print \"Data:\\n\",array\n",
    "# show the output images\n",
    "\n",
    "#for entry in data:\n",
    "    #print \"Entry: \", entry\n",
    "    #cv2.rectangle(gray, (100, 100), (1000, 1000), (0,0,0), 20)\n",
    "#cv2.namedWindow('Input', cv2.WINDOW_NORMAL)\n",
    "#cv2.imshow(\"Input\", gray)\n",
    "cv2.imwrite('/home/dries/devel/Praelexis/OCR/Output/Boxes.png',gray)\n",
    "cv2.imwrite('/home/dries/devel/Praelexis/OCR/Output/Estimation.png',newPage)\n",
    "print(\"Completed. Output in folder named 'Output'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytesseract.pytesseract??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
